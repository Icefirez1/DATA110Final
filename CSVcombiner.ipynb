{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a df that contains all the name of the CSV files in the DB\n",
    "#This is so I can filter out the names of the Years I actually want in our DB\n",
    "#ONLY RUN When first downloaded dataset (takes ~20min)\n",
    "docolnames = [\"GHCN identifier\", \"Latitude\", \"Longitude\", \"Elevation (meters)\", \"State/province\", \"Station name\", \"WMO ID\", \"First year\", \"Last year\"]\n",
    "\n",
    "csvnamesdf = pd.DataFrame(columns=docolnames)\n",
    "\n",
    "with open (\"data\\\\ghcn-m_v4_prcp_inventory.txt\", \"r\") as yaps:\n",
    "    for line in yaps:\n",
    "        csvnamesdf = pd.concat([pd.DataFrame([[line[:11], line[12:20], line[21:30], line[31:37], line[38:40], line[41:79], line[80:85], line[86:90], line[91:]]], columns=csvnamesdf.columns),csvnamesdf], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting created dataset to csv file for future use\n",
    "csvnamesdf.to_csv(\"data\\\\names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering CSV names to ones we want\n",
    "csvnamesdf = pd.read_csv(\"data\\\\names.csv\")\n",
    "\n",
    "#I saved them as strings oops\n",
    "#anyways we're using the csv files with data from at least this millenia\n",
    "csvnamesdf[\"Last year\"] = csvnamesdf[\"Last year\"].apply(lambda x: int(x))\n",
    "wantednames = csvnamesdf[csvnamesdf[\"Last year\"]>= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating all the csv files from the percipitation dataset and adding the labels\n",
    "#ONLY RUN FIRST TIME DOING CONCATENTATION (~12 hrs to run)\n",
    "colnames = [\"GHCN identifier\", \"Station name\", \"Latitude\", \"Longitude\", \"Elevation (meters)\", \"4 digit year and 2 digit month\", \"Precipitation value (tenths of a millimeter)\", \"Measurement flag\", \"Quality control flag\", \"Source flag\", \"Source index\"]\n",
    "\n",
    "directory = 'data\\ghcn-m_v4.00.00_prcp_s16970101_e20241031_c20241105'\n",
    "\n",
    "totaldf = pd.DataFrame(columns=colnames)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for filename in os.scandir(directory):\n",
    "    #only concatanating if we want it \n",
    "    try:\n",
    "        if(filename.name[:-4] in wantednames[\"GHCN identifier\"].to_list()):\n",
    "            tmpdf = pd.read_csv(filename.path, names=colnames, header=None)\n",
    "            totaldf = pd.concat([totaldf, tmpdf], ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaldf.to_csv(\"TotalPrecipout2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaldf = totaldf.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
